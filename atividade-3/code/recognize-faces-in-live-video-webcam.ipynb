{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconhecer rostos em vídeo ao vivo usando sua webcam - Simples\n",
    "\n",
    "Este é um exemplo super simples (mas lento) de executar o reconhecimento facial em vídeo ao vivo da sua webcam.\n",
    "Há um segundo exemplo que é um pouco mais complicado, mas roda mais rápido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import cv2\n",
    "from deepface import DeepFace\n",
    "import face_recognition\n",
    "from io import BytesIO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url de acesso da emotions-api\n",
    "base_url = 'http://localhost:3333'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '3c831627-d1ae-46ae-99d6-8bc1ca85e000',\n",
       "  'name': 'Lourival Oliveira Melo',\n",
       "  'avatar_url': 'http://localhost:3333/uploads/aa2803df0511-perfil-papai.jpeg'},\n",
       " {'id': 'e42ca150-ecc2-4102-b923-917ed7b1b60c',\n",
       "  'name': 'Leonaro Nunes Conçalves',\n",
       "  'avatar_url': 'http://localhost:3333/uploads/047b69e79667-perfil-leo.jpeg'},\n",
       " {'id': 'eef2855f-dfa0-4c28-a6d7-fa1ba4257d43',\n",
       "  'name': 'Igor Melo Garcia',\n",
       "  'avatar_url': 'http://localhost:3333/uploads/fcf67e515a71-perfil-igor.jpeg'},\n",
       " {'id': '364390ee-d9fb-43ef-bbfd-6a91649beff1',\n",
       "  'name': 'Miguel Ângelo Mocbel',\n",
       "  'avatar_url': 'http://localhost:3333/uploads/2e21ccb770eb-perfil-miguel.jpeg'},\n",
       " {'id': '012445df-5f0b-4957-8a3d-8bcfd5441276',\n",
       "  'name': 'Laciene Melo Garcia',\n",
       "  'avatar_url': 'http://localhost:3333/uploads/1c49fe35e4f6-IMG_20211014_090554.jpg'}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Realiza uma solicitação GET para obter a lista de usuários\n",
    "response = requests.get(f'{base_url}/user/list')\n",
    "users = response.json()\n",
    "users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializa uma lista de objetos contendo codificações faciais e nomes correspondentes\n",
    "known_faces = []\n",
    "# Itera sobre a lista de usuários\n",
    "\n",
    "for user in users:\n",
    "    # carrega a imagem do usuário\n",
    "    user_image_url = user['avatar_url']\n",
    "\n",
    "    # baixa a imagem usando requests\n",
    "    response_image = requests.get(user_image_url)\n",
    "    image_data = BytesIO(response_image.content)\n",
    "\n",
    "    # converte a imagem para um formato suportado pelo face-recognition\n",
    "    pil_image = Image.open(image_data).convert(\"RGB\")\n",
    "    user_image = np.array(pil_image)\n",
    "\n",
    "    # realiza o processo de reconhecimento facial\n",
    "    user_face_encoding = face_recognition.face_encodings(user_image)[0]\n",
    "\n",
    "    # adiciona a codificação facial o nome à lista como um objeto\n",
    "    known_faces.append({'id': user['id'], 'encoding': user_face_encoding, 'name': user['name']})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializando a webcam\n",
    "video_capture = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    # Capturando um frame do vídeo\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    # encontrando todas as faces no frame\n",
    "    face_locations = face_recognition.face_locations(frame)\n",
    "    face_encodings = face_recognition.face_encodings(frame, face_locations)\n",
    "\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        # verificando se a face é conhecida\n",
    "        matches = face_recognition.compare_faces([user['encoding'] for user in known_faces], face_encoding)\n",
    "\n",
    "        name = \"Desconhecido\"\n",
    "\n",
    "        # se uma correspondência for encontrada, use o nome correspondente\n",
    "        if True in matches:\n",
    "            first_match_index = matches.index(True)\n",
    "            name = known_faces[first_match_index]['name']\n",
    "\n",
    "        # Desenhando um retângulo ao redor do rosto\n",
    "        cv2.rectangle(frame, pt1=(left, top), pt2=(right, bottom), color=(0, 255, 0), thickness=2)\n",
    "\n",
    "        # exibindo o nome da pessoa identificada\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(frame, f\"User: {name}\", (left + 6, bottom + 40), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    # exibindo o frame resultante\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    # saindo do loop quando a tecla 'q' é pressionada\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberando os recursos\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual-environment",
   "language": "python",
   "name": "virtual-environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
